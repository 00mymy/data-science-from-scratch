{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "* Classification & Regression\n",
    "* 대표적인 Black-box 모델\n",
    "  + cf) Decision Tree\n",
    "* Brain-like\n",
    "  + Network of neurons\n",
    "  + Neuron들 사이의 연결강도(weight)에 의해 모델이 결정됨\n",
    "  + 어렵고 복잡한 문제도 잘 푼다 \n",
    "      - 복잡한 문제 &rarr; 더 많은 neuron &rarr; 더 많은 계산비용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "* Neural Network을 구성하는 기본 단위\n",
    "* Simple, single neuron (뇌세포 하나에 해당)\n",
    "* $y = f(\\sum x_iw_i$)\n",
    "    + $f$ : Step function\n",
    "    + $x$ : Inputs\n",
    "    + $w$ : weights ($w_0$ : weight for bias) \n",
    "\n",
    "![Perceptron](perceptron.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial\n",
    "import math, random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append('../common')\n",
    "from linear_algebra import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_output(weights, bias, x):\n",
    "    \"\"\"returns 1 if the perceptron 'fires', 0 if not\"\"\"\n",
    "    return step_function(dot(weights, x) + bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron으로 간단한 문제 풀기\n",
    "* Logic Gates\n",
    " \n",
    "|x|y|AND(x,y)|OR(x,y)|NOT(x)|XOR(x,y)|\n",
    "|---|---|---|---|---|---|\n",
    "|0|0|0|0|1|0|\n",
    "|0|1|0|1|1|1|\n",
    "|1|0|0|1|0|1|\n",
    "|1|1|1|1|0|0|\n",
    "\n",
    "* AND, OR, NOT Gate를 Perceptron으로 풀기\n",
    "* 문제풀기 = Weight 찾기\n",
    "\n",
    "<img src=\"simple_gates.png\" alt=\"Simple Gates\" style=\"width:600px;\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] 0\n",
      "[0, 1] 0\n",
      "[1, 0] 0\n",
      "[1, 1] 1\n"
     ]
    }
   ],
   "source": [
    "# test AND gate\n",
    "inputs = [[0,0],[0,1],[1,0], [1,1]]\n",
    "for i in inputs:\n",
    "    print(i, perceptron_output([2,2], -3, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR gate?\n",
    "* (0,1), (1,0) &rarr; 1\n",
    "* (0,0), (1,1) &rarr; 0\n",
    "\n",
    "생각처럼 쉽지 않음\n",
    "* 2차원 평면 좌표계 : XOR 값을 구별할 수 있는 하나의 직선(분할기준)을 구할 수 없다\n",
    "* 즉, 하나의 Perceptron만으로는 XOR 값을 구별할 수 없다\n",
    "* 해석적으로 풀 수는 있지만...\n",
    "    + XOR(x,y) = OR(x,y) AND (NOT(AND(x,y)))\n",
    "![XOR Gate](xor_gate_naive.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward Neural Network\n",
    "* 좀 더 체계적인 방법, 여러 개의 Perceptron을 연결하는 일반화된 구조\n",
    "* Multi-layer Perceptron (Layered Network of neurons, \"Neural Network\")\n",
    "    + Input Layer\n",
    "    + Hidden Layers (여러개)\n",
    "    + Output Layer\n",
    "* Activation function : Sigmoid\n",
    "\n",
    "![Feed-Forward Neural Network](feed_forward_nn.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return sigmoid(dot(weights, inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Step Function vs. Sigmoid Function](step_vs_sigmoid.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(neural_network, input_vector):\n",
    "    \"\"\"takes in a neural network (represented as a list of lists of lists of weights)\n",
    "    and returns the output from forward-propagating the input\"\"\"\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "\n",
    "        input_with_bias = input_vector + [1]             # add a bias input\n",
    "        output = [neuron_output(neuron, input_with_bias) # compute the output\n",
    "                  for neuron in layer]                   # for this layer\n",
    "        outputs.append(output)                           # and remember it\n",
    "\n",
    "        # the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Network 구성 - XOR Gate\n",
    "* Input Layer : Neuron 2개(입력 데이터 Feature 수 만큼) + bias\n",
    "* Hidden Layer : Neuron 2개\n",
    "    + 왜 2개인지,  Weight를 어떻게 찾았는지는 생략 (찾았다 치고!)\n",
    "* Output Layer : Neuron 1개 (0 또는 1의 값을 얻기 위함)\n",
    "\n",
    "#### Feed-Forward\n",
    "* Weight를 찾은 상태에서 결과값을 얻는 처리 과정\n",
    "\n",
    "![Neural Network for XOR](xor_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [[9.357622968839299e-14, 4.5397868702434395e-05], [9.38314668300676e-14]]\n",
      "[0, 1] [[4.5397868702434395e-05, 0.9999546021312976], [0.9999999999999059]]\n",
      "[1, 0] [[4.5397868702434395e-05, 0.9999546021312976], [0.9999999999999059]]\n",
      "[1, 1] [[0.9999546021312976, 0.9999999999999065], [9.383146683006828e-14]]\n"
     ]
    }
   ],
   "source": [
    "xor_network = [ # hidden layer\n",
    "            [[20, 20, -30], # 'and' neuron\n",
    "             [20, 20, -10]], # 'or' neuron\n",
    "            # output layer\n",
    "            [[-60, 60, -30]]] # '2nd input but not 1st input' neuron\n",
    "\n",
    "for i in inputs:\n",
    "    print(i, feed_forward(xor_network, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer의 역할\n",
    "* \"처리 단계\"와 같은 효과\n",
    "    + 단계를 거치면서 경우의 수를 줄여주는 효과\n",
    "* 복잡한 문제일수록 &rarr; 많은 Hidden Layer, 많은 Neuron &rarr; Weight를 어떻게 찾을까?\n",
    "    + 간단한 XOR Gate 문제도 Weight 찾기가 어려운데...\n",
    "\n",
    "![Hidden Layer의 역할](hidden_layer_effect.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "Weight를 구하는 기계학습 방법\n",
    "* Weight : 학습된 모델\n",
    "* Weight 구하기 : 기계학습 과정 (반복하면서, 실측치와 예측치를 비교하면서, Gradient Descent를 이용하여 조정)\n",
    "\n",
    "<ol>\n",
    "<li> Run feed_forward on an input vector to produce the outputs of all the neurons inthe network.\n",
    "<li> This results in an error for each output neuron—the difference between its output and its target.\n",
    "<li> Compute the gradient of this error as a function of the neuron’s weights, and adjust its weights in the direction that most decreases the error.\n",
    "<li> “Propagate” these output errors backward to infer errors for the hidden layer.\n",
    "<li> Compute the gradients of these errors and adjust the hidden layer’s weights in the same manner.\n",
    "</ol>\n",
    "\n",
    "<img align=\"left\"  src=\"backprop.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "<img align=\"left\"  src=\"backprop_ex.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagate(network, input_vector, target):\n",
    "\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # the output * (1 - output) is from the derivative of sigmoid\n",
    "    output_deltas = [output * (1 - output) * (output - target[i])\n",
    "                     for i, output in enumerate(outputs)]\n",
    "\n",
    "    # adjust weights for output layer (network[-1])\n",
    "    for i, output_neuron in enumerate(network[-1]):\n",
    "        for j, hidden_output in enumerate(hidden_outputs + [1]):\n",
    "            output_neuron[j] -= output_deltas[i] * hidden_output\n",
    "\n",
    "    # back-propagate errors to hidden layer\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                      dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # adjust weights for hidden layer (network[0])\n",
    "    for i, hidden_neuron in enumerate(network[0]):\n",
    "        for j, input in enumerate(input_vector + [1]):\n",
    "            hidden_neuron[j] -= hidden_deltas[i] * input\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input):\n",
    "    return feed_forward(network, input)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예 - 난이도 下) XOR 다시 풀어보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0] [0.01]\n",
      "[0, 1] [0.99]\n",
      "[1, 0] [0.99]\n",
      "[1, 1] [0.01]\n"
     ]
    }
   ],
   "source": [
    "inputs = [[0,0],[0,1],[1,0], [1,1]]\n",
    "targets = [[0], [1], [1], [0]]\n",
    "\n",
    "# network 초기화 (Random weights)\n",
    "hidden_layer = [[random.random(),random.random(),random.random()],[random.random(),random.random(),random.random()]] # 2 neurons + bias\n",
    "output_layer = [[random.random(),random.random(), random.random()]] # 1 output neuron + bias \n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "for __ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)\n",
    "\n",
    "for i, input in enumerate(inputs):\n",
    "    outputs = predict(input)\n",
    "    print(input, [round(p,2) for p in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예 - 난이도 中) 이 일은 이, 이 이는 사, 이 삼은 육, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 0] [0.99, 0.01, 0.04, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 1] [0.02, 0.01, 0.94, 0.01, 0.04, 0.01, 0.0, 0.01, 0.0, 0.01, 0.0, 0.01, 0.0, 0.01, 0.0, 0.0, 0.0, 0.01, 0.0, 0.01]\n",
      "[2, 2] [0.0, 0.0, 0.04, 0.0, 0.94, 0.0, 0.03, 0.0, 0.01, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 3] [0.0, 0.0, 0.0, 0.0, 0.04, 0.0, 0.87, 0.0, 0.38, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 4] [0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.04, 0.0, 0.33, 0.0, 0.04, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 5] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.22, 0.0, 0.74, 0.0, 0.37, 0.0, 0.04, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 6] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.13, 0.0, 0.62, 0.0, 0.38, 0.0, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[2, 7] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11, 0.0, 0.18, 0.0, 0.16, 0.0, 0.01, 0.0]\n",
      "[2, 8] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09, 0.0, 0.22, 0.0, 0.29, 0.0, 0.41, 0.0]\n",
      "[2, 9] [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09, 0.0, 0.22, 0.0, 0.29, 0.0, 0.42, 0.0]\n"
     ]
    }
   ],
   "source": [
    "input_size = 2  # [2,0], [2,1], [2,2], ...\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 20 # 0~ 29\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for __ in range(input_size + 1)]\n",
    "                for __ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for __ in range(num_hidden + 1)]\n",
    "                for __ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]\n",
    "\n",
    "# [2,0], [2,1], [2,2], ...\n",
    "inputs = [[2,i] for i in range(10)]\n",
    "\n",
    "# [2,0] ==> [1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "# [2,1] ==> [0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "targets = [[1 if i == j*2 else 0 for i in range(20)] for j in range(10)]\n",
    "\n",
    "\n",
    "for __ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)\n",
    "\n",
    "for i, input in enumerate(inputs):\n",
    "    outputs = predict(input)\n",
    "    print(input, [round(p,2) for p in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.07, 0.0, 0.81, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print([round(p,2) for p in predict([2, 2.5])])\n",
    "\n",
    "# [2, 2.1], [2, 2.7], .... (다른 입력값에 대해서도 테스트해 보자)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예 - 난이도 上) 숫자 이미지 인식\n",
    "* 5x5 이미지 &rarr; 숫자\n",
    "![CAPCHA](capcha.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "    raw_digits = [\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             1...1\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\n",
    "             ..1..\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             1....\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"1...1\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1....\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\n",
    "             ....1\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             1...1\n",
    "             11111\"\"\",\n",
    "\n",
    "          \"\"\"11111\n",
    "             1...1\n",
    "             11111\n",
    "             ....1\n",
    "             11111\"\"\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11111\\n         1...1\\n         1...1\\n         1...1\\n         11111'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_digits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 간단한 전처리\n",
    "* 이미지 &rarr; 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_digit(raw_digit):\n",
    "    return [1 if c == '1' else 0\n",
    "            for row in raw_digit.split(\"\\n\")\n",
    "            for c in row.strip()]\n",
    "\n",
    "inputs = list(map(make_digit, raw_digits))\n",
    "targets = [[1 if i == j else 0 for i in range(10)]\n",
    "           for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1]\n",
      "[1, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 1]\n",
      "[1, 0, 0, 0, 1]\n",
      "[1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# 예쁘게 그려보기\n",
    "for i in range(5):\n",
    "    at = i*5\n",
    "    print(inputs[0][at:at+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Net 구성 &rarr; 학습시키기\n",
    "* input_size : 25  (5x5)\n",
    "* num_hidden : 5   (5 neurons)\n",
    "* output_size : 10 (0~9)\n",
    "![CAPCHA- Neural Net 구성](capcha_network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)   # to get repeatable results\n",
    "input_size = 25  # each input is a vector of length 25\n",
    "num_hidden = 5   # we'll have 5 neurons in the hidden layer\n",
    "output_size = 10 # we need 10 outputs for each input\n",
    "\n",
    "# each hidden neuron has one weight per input, plus a bias weight\n",
    "hidden_layer = [[random.random() for __ in range(input_size + 1)]\n",
    "                for __ in range(num_hidden)]\n",
    "\n",
    "# each output neuron has one weight per hidden neuron, plus a bias weight\n",
    "output_layer = [[random.random() for __ in range(num_hidden + 1)]\n",
    "                for __ in range(output_size)]\n",
    "\n",
    "# the network starts out with random weights\n",
    "network = [hidden_layer, output_layer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for __ in range(10000):\n",
    "    for input_vector, target_vector in zip(inputs, targets):\n",
    "        backpropagate(network, input_vector, target_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인 (1) - 원래 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.96, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.03, 0.0]\n",
      "1 [0.0, 0.96, 0.03, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "2 [0.0, 0.02, 0.96, 0.0, 0.0, 0.03, 0.0, 0.0, 0.0, 0.0]\n",
      "3 [0.0, 0.03, 0.0, 0.97, 0.0, 0.0, 0.0, 0.02, 0.0, 0.03]\n",
      "4 [0.0, 0.02, 0.0, 0.0, 0.99, 0.0, 0.0, 0.01, 0.0, 0.0]\n",
      "5 [0.0, 0.0, 0.02, 0.0, 0.0, 0.96, 0.01, 0.0, 0.02, 0.02]\n",
      "6 [0.0, 0.0, 0.01, 0.0, 0.01, 0.01, 0.99, 0.0, 0.0, 0.0]\n",
      "7 [0.02, 0.0, 0.0, 0.02, 0.0, 0.0, 0.0, 0.97, 0.0, 0.0]\n",
      "8 [0.03, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.0, 0.96, 0.03]\n",
      "9 [0.0, 0.0, 0.0, 0.01, 0.0, 0.02, 0.0, 0.0, 0.03, 0.95]\n"
     ]
    }
   ],
   "source": [
    "for i, input in enumerate(inputs):\n",
    "    outputs = predict(input)\n",
    "    print(i, [round(p,2) for p in outputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인 (2) - 훼손된 이미지, 필기체\n",
    "![훼손된 이미지](ugly_image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.94, 0.0, 0.0, 0.0, 0.01, 0.0, 0.13]\n"
     ]
    }
   ],
   "source": [
    "print([round(x, 2) for x in\n",
    "      predict(  [0,1,1,1,0,    # .@@@.\n",
    "                 0,0,0,1,1,    # ...@@\n",
    "                 0,0,1,1,0,    # ..@@.\n",
    "                 0,0,0,1,1,    # ...@@\n",
    "                 0,1,1,1,0])]) # .@@@."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.59, 0.0, 0.0, 0.95, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print([round(x, 2) for x in\n",
    "      predict(  [0,1,1,1,0,    # .@@@.\n",
    "                 1,0,0,1,1,    # @..@@\n",
    "                 0,1,1,1,0,    # .@@@.\n",
    "                 1,0,0,1,1,    # @..@@\n",
    "                 0,1,1,1,0])]) # .@@@."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 딥 러닝 (Deep Learning)\n",
    "* Deep Neural Networks (DNN)\n",
    "* Input Size가 크다, Output Size도 크다, 여러 층의 Hidden Layer, 많은 수의 Neuron\n",
    "* Large network &rarr; 많은 컴퓨팅 자원 필요\n",
    "* H/W 발전 + 컴퓨팅 기술 발전 + ML 기술 발전 &rarr; 딥 러닝 가능 &rarr; 복잡하고 어려운 문제도 풀 수 있게 됨\n",
    "* 여러 가지 발전된 모델들\n",
    "    + Convolutional Deep Neural Networks(CDNN)\n",
    "    + Recurrent Neural Networks (RNN)\n",
    "    + Deep Belief Networks (DBN)\n",
    "* 좋은 구현 도구들\n",
    "    + TensorFlow, Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
