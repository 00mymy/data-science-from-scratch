{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier\n",
    "* Classiifer : Yes or No, Categorical Classification\n",
    "* (매우 유명하고 오래된) 확률 기반의 예측기\n",
    "* 중요한 가정\n",
    "  + 모든 특성값은 서로 독립\n",
    "  + 예) 키와 몸무게 특성값을 바탕으로 비만여부를 판단하는 예측기\n",
    "      - '키'와 '몸무게'는 서로 연관성이 없다고 가정\n",
    "  + 실제로는 연관성이 있는 경우가 많음에도 불구하고 그렇다고 가정 (매우 Naive한 가정)\n",
    "      - Naive한 가정 덕분에 예측 모델이 비교적 간단하고 이해하기 쉬운 편\n",
    "      - 비록 Naive한 가정이지만, 많은 분류/예측 문제에서 비교적 잘 돌아감!\n",
    "* 참고\n",
    "  + [나이브 베이즈 분류(위키)](https://ko.wikipedia.org/wiki/%EB%82%98%EC%9D%B4%EB%B8%8C_%EB%B2%A0%EC%9D%B4%EC%A6%88_%EB%B6%84%EB%A5%98)\n",
    "  + [베이즈 정리(위키)](https://ko.wikipedia.org/wiki/%EB%B2%A0%EC%9D%B4%EC%A6%88_%EC%A0%95%EB%A6%AC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 모델\n",
    "$p(C_k|\\mathbf{x})={{p(C_k)p(\\mathbf{x}|C_k)}\\over{p(\\mathbf{x})}}$\n",
    "* $\\mathbf{x}$\n",
    "  + 입력값 (특성값, Feature Vector)\n",
    "  + 예) 과목별 점수\n",
    "* $p(C_k)|\\mathbf{x})$\n",
    "  + 출력값 (클래스, 카테고리)\n",
    "    - 입력값 $\\mathbf{x}$가 주어졌을 때, 우리가 얻고자하는 예측 결과값\n",
    "  + 입력으로 주어진 Feature Vector $\\mathbf{x}$가 클래스(카테고리) $p(C_k)$에 속할 확률\n",
    "  + 클래스 $C_1$, $C_2$, ...., $C_k$ 각각에 속할 확률을 구할 수 있다\n",
    "  + 예) 과목별 점수 (입력) &rarr; 합격할 확률, 불합격 확률\n",
    "* $p(C_k)$\n",
    "  + 임의의 데이터 포인트가 클래스 $C_k$에 속할 확률\n",
    "  + 전체 데이터셋을 클래스별로 카운트하여 구하면 된다 (트레이닝 데이터셋에서 미리 구해 놓을 수 있음)\n",
    "  + 예) 전체 지원자 중 합격자 35%, 불합격자 65%\n",
    "* $p(\\mathbf{x}|C_k)$\n",
    "  + 클래스 $C_k$에서 Feature Vector $\\mathbf{x}$가 나타날 확률\n",
    "  + 예) 합격자 중에서 영어 성적이 80점일 확률 (또는 등급이 A일 확률)\n",
    "  + 각 Feature는 서로 독립적이라고 가정하였으므로 아래와 같이 구할 수 있다\n",
    "    - $p(\\mathbf{x_1}|C_k)p(\\mathbf{x_2}|C_k)...p(\\mathbf{x_n}|C_k)$\n",
    "    - 각각의 $p(\\mathbf{x_i}|C_k)$ 값은 트레이닝 데이터셋에서 미리 구해 놓을 수 있음\n",
    "    - 이산(Discrete) 값일 때는 클래스 $C_k$에 속하는 데이터 포인트들에 대해서, 각각의 Feature 값 $\\mathbf{x_i}$를 카운트하여 구하면 된다. (예, A/B/C/D/F 등급)\n",
    "    - 연속적인 값일 때는 확률분포를 알면 됨 (예, 평균 60이고 표준편차가 10인 정규분포라 가정)\n",
    "* $p(\\mathbf{x})$\n",
    "  + 클래스 $C_k$에 영향을 받지 않는 값\n",
    "    - $p(C_k)|\\mathbf{x})$를 판단하는 식에서 고정값(상수)이나 마찬가지 ($C_1$, $C_2$에 대해서 같은 분모값임)\n",
    "  + 주어진 Input Feature($x_1, x_2,...,x_n$)에 대해, 여러 카테고리 중에 어디에 속할 가능성이 가장 높은지만 판단할 수 있으면 된다\n",
    "    - 어차피 Naive 가정이 있기 때문에 정확한 확률값을 구하는 것은 의미가 없다\n",
    "    - 굳이 확률을 구할 필요가 없는 값 (그냥 분모 $\\mathbf{x}$는 무시해도 된다)\n",
    "  \n",
    "\n",
    "### 요약하면\n",
    "* $p(C_k)$, $p(\\mathbf{x}|C_k)$을 트레이닝 데이터셋에서 미리 구해 놓으면 (트레이닝하기)\n",
    "* 입력 Feature Vector $\\mathbf{x}$에 대해 $p(C_k)|\\mathbf{x})$를 구할 수 있다 (예측하기)\n",
    "  - 예측 클래스 &rarr; $\\mathbf{x}$ 가 속할 확률이 가장 높은 클래스 &rarr; $C_1$, $C_2$, ...., $C_k$ 중에서 가장 큰 값을 가지는 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Really Dumb Spam Filter\n",
    "\n",
    "###  \"bitcoin\"이란 단어가 있는 메시지가 스팸일 확률\n",
    "+ Bayes's theorem 이용하여 구해보자 (조건부 확률 구하기)\n",
    "+ $P(S|B)={{P(B|S)P(S)}\\over{P(B|S)P(S)+P(B|\\neg S)P(\\neg S)}}$\n",
    "+ 아래의 확률을 구하면 $P(S|B)$를 구할 수 있다\n",
    "  - $P(B|S)P(S)$: 스팸 메시지면서 \"bitcoin\"이 들어있을 확률\n",
    "  - $P(B|S)P(S)+P(B|\\neg S)P(\\neg S)$: 메시지에 \"bitcoin\"이 들어있을 확률 (스팸이든 아니든)\n",
    "+ 스팸 여부를 알고있는 메시지들의 데이터셋이 있다면, 위의 확률들을 구할 수 있음\n",
    "+ 예) 전체 메시지 중 50%는 스팸이고, 스팸 메시지의 50%에는 \"bitcoin\"이란 단어가 나오며, 스팸이 아닌 메시지의 1%에 \"bitcoin\"이 등장\n",
    "  - $P(S)=P(\\neg S)=0.5$\n",
    "  - $P(B|S)=0.5$\n",
    "  - $P(B|\\neg S)=0.01$\n",
    "  - $P(S|B)={{0.5*0.5}\\over{0.5*0.5 + 0.5*0.01}}=0.98$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A More Sophisticated Spam Filter\n",
    "* Vocabulary\n",
    "  + $w_1, w_2, ..., w_n$\n",
    "  + 메시지 데이터셋에 등장하는 모든 단어들의 목록 (어휘사전)\n",
    "* $X_i$\n",
    "  + \"메시지에 Vocabulary의 $i$번채 단어($w_i$)가 들어있다\"는 사건\n",
    "* $P(X_i|S)$\n",
    "  + 스팸 메시지에 $w_i$가 들어있을 확률\n",
    "* $P(X_i|\\neg S)$\n",
    "  + 스팸이 아닌 메시지에 $w_i$가 들어있을 확률\n",
    "* $P(X_1=x_1, X_2=x_2, ... X_n=x_n|S)$\n",
    "  + 스팸 메시지를 구성하는 단어들이 $X_1=x_1, X_2=x_2, ... X_n=x_n$과 같이 나타날 확률\n",
    "    - $x_i$: 단어 $w_i$가 등장하면 \"1\", 등장하지 않으면 \"0\"\n",
    "  + Naive Bayes Classifier 모델에서는 단어 사이에 연관성이 없다고 가정 (서로 독립적이라고 가정)\n",
    "    - $P(X_1=x_1, X_2=x_2, ... X_n=x_n|S) = P(X_1=x_1|S)P(X_2=x_2|S)...P(X_n=x_n|S)$\n",
    "  + 예) 스팸 메시지의 50%에 \"bitcoin\"이라는 단어가 등장하고, 나머지 50%에는\"rolex\"가 등장할 때\n",
    "    - \"bitcoin\"과 \"rolex\"만으로 구성된 Vocabulry가 있다고 가정 \n",
    "    - 스팸 메시지에 두 단어가 모두 등장할 확률은?\n",
    "    -  $P(X_1=1, X_2=1|S) = P(X_1=1|S)P(X_2=1|S) = 0.5*0.5 = 0.25$\n",
    "* 위 확률들을 구할 수 있으므로 다음의 확률을 구할 수 있다.\n",
    "  + $P(S|X_1=x_1, X_2=x_2, ... X_n=x_n) ={{P(X_1=x_1, X_2=x_2, ... X_n=x_n|S)P(S)}\\over{P(X_1=x_1, X_2=x_2, ... X_n=x_n|S)P(S) + P(X_1=x_1, X_2=x_2, ... X_n=x_n|\\neg S)P(\\neg S)}}$\n",
    "  + 어떤 메시지를 구성하는 단어들이 $X_1=x_1, X_2=x_2, ... X_n=x_n$와 같이 나타날 때, 이 메시지가 스팸 메시지일 확률\n",
    "  + 만들고자하는 스팸 메시지 예측기!\n",
    "    - $P(S|X) ={{P(X|S)P(S)}\\over{P(X|S)P(S) + P(X|\\neg S)P(\\neg S)}}$\n",
    "    - 트레이닝: $P(X|S)$, $P(S)$, $P(X|\\neg S)$를 구할 수 있도록 미리 계산해 놓기\n",
    "    - 입력: $X$ &rarr; 출력: $P(S|X)$ (입력 메시지 $X$가 스팸일 확률)\n",
    " \n",
    "  \n",
    "### Underflow 방지\n",
    "* $P(X_i=x_i|S)$는 0~1 사이의 작은 값\n",
    "* 따라서, $P(X_1=x_1|S)P(X_2=x_2|S)...P(X_n=x_n|S)$는 매우 작은 값이 될 것이다 (거의 0에 가까운 값. Underflow 문제 발생)\n",
    "  + Vocabulary에는 메시지 데이터셋에 등장하는 모든 단어가 포함됨 ($n$이 상당히 크다)\n",
    "* $\\log(ab)=\\log(a) + \\log(a)$ 공식을 이용\n",
    "  + $p_1*p_2*...p_n = \\exp(\\log(p_1) + \\log(p_2) + ... + \\log(p_n))$\n",
    "  + Log 공식을 이용하여 곱셈 대신 덧셈으로 계산하면 underflow 문제를 피할 수 있다\n",
    "  \n",
    "### 확률이 0이되는 것 방지\n",
    "* 만약 단어 \"data\"가 스팸이 아닌 모든 메시지에서만 나타나고 스팸 메시지에서는 전혀 나타나지 않는다면?\n",
    "  + $P(data|S) = 0$ &rarr; \"data\"가 등장하는 모든 메시지를 스팸이 아니라고 판단할 것이다\n",
    "* $P(X_i|S)$ = ($k$ + number of spams containing $w_i$)/($2k$ + number of spams)\n",
    "  + $k$: pseudocount\n",
    "  + $P(X_i|\\neg S)$도 같은 방식으로 구한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "### 전처리\n",
    "* 메시지 텍스트 &rarr; 단어(word)로 분해\n",
    "* 메시지 원문에는 대소문자가 섞여있음 &rarr; 소문자로 통일\n",
    "* 메시지 원문에는 같은 단어가 여러번 나타남 &rarr; 중복제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set\n",
    "import re\n",
    "\n",
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower()                         # Convert to lowercase,\n",
    "    all_words = re.findall(\"[a-z0-9']+\", text)  # extract the words, and\n",
    "    return set(all_words)                       # remove duplicates.\n",
    "\n",
    "assert tokenize(\"Data Science is science\") == {\"data\", \"science\", \"is\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트레이닝 데이터 자료구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaiveBayesClassifier\n",
    "* Constructor\n",
    "  + pseudocount 설정\n",
    "* Methods\n",
    "  + train()\n",
    "    - 학습(훈련)용 데이터셋을 처리하여 predictor에서 스팸 확률을 계산할 수 있도록 준비\n",
    "    - 확률 계산에 필요한 변수값 및 카운트값 처리\n",
    "  + _probabilities()\n",
    "    - 토큰(메시지를 구성하는 개별 단어)에 대해 스팸 확률 계산\n",
    "  + predict()\n",
    "    - 새로운 메시지 입력에 대해 스팸 확률 반환\n",
    "    - _probabilities()가 반환하는 토큰별 스팸 확률을 이용하여 해당 메시지의 스팸확률 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k  # smoothing factor\n",
    "\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "\n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            # Increment message counts\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "\n",
    "            # Increment word counts\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "\n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"returns P(token | spam) and P(token | not spam)\"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "\n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "\n",
    "        return p_token_spam, p_token_ham\n",
    "\n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "\n",
    "        # Iterate through each word in our vocabulary.\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "\n",
    "            # If *token* appears in the message,\n",
    "            # add the log probability of seeing it;\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "\n",
    "            # otherwise add the log probability of _not_ seeing it\n",
    "            # which is log(1 - probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "\n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam / (prob_if_spam + prob_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Our Model\n",
    "* 간단한 텍스트로 구성된 메시지를 이용하여 기능 테스트\n",
    "  + Training 데이터셋 특징: 텍스트에 \"spam\" 이라는 단어가 있으면 &rarr; is_spam=True\n",
    "      - \"spam rules\" &rarr; is_spam=True\n",
    "      - \"ham rules\" &rarr; is_spam=False\n",
    "      - \"hello ham\" &rarr; is_spam=False\n",
    "  + 예상) \"hello spam\"가 같이 \"spam\"이라는 단어가 포함된 메시지가 주어졌을 때, \"스팸\"이라고 판단할까?\n",
    "* Training &rarr; Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "            Message(\"ham rules\", is_spam=False),\n",
    "            Message(\"hello ham\", is_spam=False)]\n",
    "\n",
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)\n",
    "\n",
    "assert model.tokens == {\"spam\", \"ham\", \"rules\", \"hello\"}\n",
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2\n",
    "assert model.token_spam_counts == {\"spam\": 1, \"rules\": 1}\n",
    "assert model.token_ham_counts == {\"ham\": 2, \"rules\": 1, \"hello\": 1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 손으로 계산하면서 검증해 보자\n",
    "* 테스트 메시지가 주어졌을 때, 손으로 계산한 예측값과 구현한 메쏘드의 결과가 동일한가 검증\n",
    "* 복습\n",
    "  + 스팸 메시지에 단어(토근, word) $w_i$가 들어있을 확률\n",
    "    - $P(X_i|S)$ = ($k$ + number of spams containing $w_i$)/($2k$ + number of spams)\n",
    "  + 만찬가지로... 스팸이 아닌 메시지에 대해서...\n",
    "    - $P(X_i|\\neg S)$ = ($k$ + number of non-spams containing $w_i$)/($2k$ + number of non-spams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "probs_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5),      # \"spam\"  (present)\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5),  # \"ham\"   (not present)\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5),  # \"rules\" (not present)\n",
    "    (0 + 0.5) / (1 + 2 * 0.5)       # \"hello\" (present)\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5),      # \"spam\"  (present)\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5),  # \"ham\"   (not present)\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5),  # \"rules\" (not present)\n",
    "    (1 + 0.5) / (2 + 2 * 0.5),      # \"hello\" (present)\n",
    "]\n",
    "\n",
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))\n",
    "\n",
    "# Should be about 0.83\n",
    "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Our Model\n",
    "* 큰 데이터셋, 실데이터 기반으로 돌려보자\n",
    "* SpamAssassin public corpus\n",
    "  + https://spamassassin.apache.org/old/publiccorpus\n",
    "* 메일의 제목을 보고 스팸 여부를 판단\n",
    "  + 가져온 데이터(이메일)에서 제목과 스팸여부만 추출하여 데이터셋 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, re\n",
    "\n",
    "# modify the path to wherever you've put the files\n",
    "path = '/Work/python/data-science-from-scratch/data/Spam_Assassin_Files/*/*'\n",
    "#path = '..'\n",
    "\n",
    "data: List[Message] = []\n",
    "\n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "\n",
    "    # There are some garbage characters in the emails, the errors='ignore'\n",
    "    # skips them instead of raising an exception.\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break  # done with this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3300"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(text='Re: The case for spam\\n', is_spam=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 잠깐!\n",
    "* 교재의 원본 패키지와 notebook 파일의 디렉토리가 다를 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'scratch' package가 설치된 디렉토리로 작업 디렉토리 바꿈 (package를 import하기 위함)\n",
    "import os, sys\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 드디어, 진짜 테스트\n",
    "* 트레이닝 데이터셋과 테스트 데이터셋으로 나누기\n",
    "* 트레이닝 데이터셋으로 훈련/학습시키기\n",
    "* 테스트 데이터셋으로 예측성능 측정해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scratch.machine_learning import split_data\n",
    "\n",
    "random.seed(0)      # just so you get the same answers as me\n",
    "train_messages, test_messages = split_data(data, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475, 825)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_messages), len(test_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({(False, False): 669, (True, True): 86, (True, False): 40, (False, True): 30})\n"
     ]
    }
   ],
   "source": [
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "predictions = [(message, model.predict(message.text))\n",
    "               for message in test_messages]\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                           for message, spam_probability in predictions)\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix 해석\n",
    "* (False, False): 스팸이 아닌것을 스팸이 아니라고 판단 (정답. True Negative)\n",
    "* (True, True): 스팸인것을 스팸이라고 판단 (정답. True Positive)\n",
    "* (True, False): 스팸인것을 스팸이 아니라고 판단 (오답. False Negative)\n",
    "* (False, True): 스팸이 아닌것을 스팸이라고 판단 (오답. False Positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7413793103448276\n",
      "Recall: 0.6825396825396826\n"
     ]
    }
   ],
   "source": [
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "tn = confusion_matrix[(False, False)]\n",
    "tp = confusion_matrix[(True, True)]\n",
    "fn = confusion_matrix[(True, False)]\n",
    "fp = confusion_matrix[(False, True)]\n",
    "\n",
    "print( \"Precision:\", precision(tp, fp, fn, tn))\n",
    "print( \"Recall:\", recall(tp, fp, fn, tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과를 좀 더 살펴보자\n",
    "* 스팸일 확률이 높은 단어들은 무엇일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['assistance', 'attn', '95', 'money', 'per', 'clearance', 'sale', 'rates', 'systemworks', 'adv']\n",
      "hammiest_words ['spambayes', 'users', 'razor', 'zzzzteana', 'sadev', 'apt', 'perl', 'ouch', 'spamassassin', 'selling']\n"
     ]
    }
   ],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # We probably shouldn't call private methods, but it's for a good cause.\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "\n",
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t, model))\n",
    "\n",
    "print(\"spammiest_words\", words[-10:])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 더 나은 스팸 필터를 만들려면?\n",
    "* 더 많은(다양한) 트레이닝 데이터셋으로 훈련\n",
    "* 메일의 제목뿐만 아니라 본문도 고려\n",
    "* 최소 몇 번 이상 등장하는 단어들만 고려 (min_count)\n",
    "* stemmer\n",
    "  + 같은 또는 비슷한 단어는 하나로 통일시킴\n",
    "  + 예) cheap & cheepest, words & word\n",
    "  + 참고 - https://tartarus.org/martin/PorterStemmer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
